{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3081a35e",
   "metadata": {},
   "source": [
    "# Week 1 Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ecc73",
   "metadata": {},
   "source": [
    "## Hugging Face\n",
    "\n",
    "### What are some common natural language processing tasks?\n",
    "\n",
    "Let's explore some of the interesting pre-trained models on Hugging Face hub.\n",
    "\n",
    "Make sure the `transformers` library is installed. If the next cell works, you're good. Otherwise\n",
    "`conda install transformers` or `pip install transformers`. You can do a few exercises\n",
    "while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc81e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9930330",
   "metadata": {},
   "source": [
    "Look up https://huggingface.co/docs/transformers/en/main_classes/pipelines and find the \n",
    "documentation for the `pipeline` constructor.\n",
    "\n",
    "Make a list of tasks that look relevant to natural language processing. Randomly pick one \n",
    "and look up more information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87c40bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text\u001b[38;5;241m-\u001b[39mclassification\n\u001b[0;32m      2\u001b[0m MiniLMv2\u001b[38;5;241m-\u001b[39mtoxic\u001b[38;5;241m-\u001b[39mjigsaw\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text-classification\n",
    "MiniLMv2-toxic-jigsaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba611701",
   "metadata": {},
   "source": [
    "Go to the Hugging Face hub and find a model that implements the task that you saw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b9336",
   "metadata": {},
   "source": [
    "### Running some example models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31822203",
   "metadata": {},
   "source": [
    "Look up the following dataset:\n",
    "\n",
    "- sst2\n",
    "\n",
    "(You can look it up on Hugging Face, or just search in general.)\n",
    "\n",
    "What is it about? What are the features (columns) of this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b075f918",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m idx, sentence, label\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "idx, sentence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c55d9",
   "metadata": {},
   "source": [
    "Look up the following models:\n",
    "\n",
    "- distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "You can probably guess what dataset it has been fine-tuned on! What sort of task is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d4e4e",
   "metadata": {},
   "source": [
    "You can use it with `transformers.pipeline(` *name-of-the-task* `,model=\"` *name-of-the-model* `)`\n",
    "\n",
    "Try the following:\n",
    "\n",
    "- Write a grumpy sentence and see what it says.\n",
    "\n",
    "- Write a cheery and happy sentence\n",
    "\n",
    "- Write a neutral sentence but include the name of developed nation or popular city\n",
    "\n",
    "- Write a neutral sentence but include the name of undeveloped nation or a city that has a bad reputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0320a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\47976586\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b353f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.pipeline('text-classification',model = 'distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5117ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9994398951530457}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998801946640015}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9952318072319031}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9954913258552551}]\n"
     ]
    }
   ],
   "source": [
    "print(model('I am grumpy'))\n",
    "print(model('I am happy'))\n",
    "print(model('I have been to India'))\n",
    "print(model('I live in Spain but the S is silent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a96313",
   "metadata": {},
   "source": [
    "Look up the  **conll03** dataset.\n",
    "\n",
    "We can create a pipeline with the \"ner\" task. The default model has been trained on **conll03**\n",
    "\n",
    "Copy and paste a news article from today's news and do ner (named entity recognition) on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f6446ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner = transformers.pipeline('ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d43ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-LOC', 'score': 0.99503386, 'index': 8, 'word': 'Sydney', 'start': 50, 'end': 56}]\n"
     ]
    }
   ],
   "source": [
    "print(ner(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "702e1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = 'Police officer facing murder charges over missing Sydney couple'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01881bdc",
   "metadata": {},
   "source": [
    "Look up the **SQuAD** dataset.\n",
    "\n",
    "The question-answering task is a little different. The pipeline takes two arguments:\n",
    "\n",
    "- question (the question you want to ask)\n",
    "\n",
    "- context (the information that it has to answer questions about)\n",
    "\n",
    "Ask a question about your news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d77c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "QA = transformers.pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd171b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6904413104057312,\n",
       " 'start': 0,\n",
       " 'end': 14,\n",
       " 'answer': 'Spidermans dad'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"question\" : \"Who is facing murder charges ?\", \"context\" : \"Spidermans dad is a police\"}\n",
    "QA(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77fcbc",
   "metadata": {},
   "source": [
    "Summarise your news article using the default model for the \"summarize\" task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbc9a0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed4418bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length=56 must be inferior than your max_length=20.\n",
      "C:\\Users\\47976586\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1279: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (20). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Darryl George, 18, has not been in his regular Houston-area high'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer('''A Black high school students months-long punishment by his Texas school district for refusing to change his hairstyle does not violate a new state law that prohibits race-based hair discrimination, a judge ruled on Thursday.\n",
    "Darryl George, 18, has not been in his regular Houston-area high school classes since August 31 because the district, Barbers Hill, says the length of his hair violates its dress code.\n",
    "The district filed a lawsuit arguing Georges long hair, which he wears in tied and twisted locs on top of his head, violates its policy because it would fall below his shirt collar, eyebrows or earlobes when let down.''', max_length=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b9724",
   "metadata": {},
   "source": [
    "Translate it into another language. The name of the task will be something like\n",
    "\"translation_en_to_de\" (\"de\" is the language code for Germany). Pick your favourite\n",
    "language.\n",
    "\n",
    "Note that you will have to specify a model. Helsinki-NLP is a good place to start searching\n",
    "for on. You might have to install some supporting packages like `sentencepiece`\n",
    "(and then you will have to restart the jupyter notebook kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066bd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf5fc12",
   "metadata": {},
   "source": [
    "OpenAI have a remarkably good speech-to-text model called \"whisper\".\n",
    "\n",
    "The task is called \"automatic-speech-recognition\". There is a good model called \"openai/whisper-small\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa96b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae443f24",
   "metadata": {},
   "source": [
    "#### Speech generation\n",
    "\n",
    "ElevenLabs.io just raised $80m and have a billion dollar valuation turning text into speech!\n",
    "\n",
    "The quality of the default model in Hugging Face isn't quite that good though.\n",
    "\n",
    "The name of the task is \"text-to-audio\". Make up a sentence and run it. It outputs a dictionary with two keys:\n",
    "\n",
    "- `audio` (a 2D numpy array, but because it's mono audio data there's only one real axis)\n",
    "\n",
    "- `sampling_rate` just a number\n",
    "\n",
    "If you install the `soundfile` package, you'll be able to run\n",
    "\n",
    "```python\n",
    "import soundfile as sf\n",
    "sf.write('output.wav', audio_out['audio'].T, audio_out['sampling_rate'])\n",
    "```\n",
    "\n",
    "Assuming your computer has a speaker, you can then find the `output.wav` file and play it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccacfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4a3416c",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "In the lectures, we finished up talking about how PyTorch doesn't have a built-in `.fit()` or `.train()`\n",
    "method.\n",
    "\n",
    "The code below has a training loop, but it has a fixed number of iterations.\n",
    "\n",
    "Change it so that it has a validation dataset, and that it stops training when the accuracy\n",
    "on the validation dataset is no longer improving.\n",
    "\n",
    "To do this, you will make use of \n",
    "- `model.eval()`  This doesn't evaluate anything! It just tells the model that you are in\n",
    "   evaluation mode.\n",
    "- `model.train()` Likewise, doesn't train, it just tells the model that you are \n",
    "   switching back to training mode.\n",
    "- `with torch.no_grad():` speeds up calculations by not trying to get gradients (which would\n",
    "   be irrelevant for the test set).\n",
    "- `loss.item()` get a float out for the loss\n",
    "- `model()` this is how you do inference on a model: call it like a function.\n",
    "\n",
    "For your own sanity you will probably want to split this code up into a few cells, print out\n",
    "some messages in each batch (or at least each epoch).\n",
    "\n",
    "Optional bonus exercises:\n",
    "\n",
    "- According to your model, what was the probability that a 3rd-class male passenger would die? What about a 1st-    class female passenger?\n",
    "\n",
    "- Visualise how the weights of the first layer of this model change over time.\n",
    "\n",
    "- Make the model work better. It's particularly inaccurate at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.dropna(inplace=True)\n",
    "X = df.drop('Survived', axis=1).select_dtypes(include=['float64', 'int64']).values\n",
    "y = df['Survived'].values\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Neural network architecture\n",
    "class TitanicNN(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TitanicNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(input_size, 64)\n",
    "        self.layer2 = torch.nn.Linear(64, 32)\n",
    "        self.layer3 = torch.nn.Linear(32, 2)\n",
    "        # That last one is a binary classifier\n",
    "        # Don't need softmax, CrossEntropyLoss handles it\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "# We want to capture \n",
    "evolution = []\n",
    "    \n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = TitanicNN(X_train.shape[1])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a989c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
